import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models, transforms, datasets

from torch.profiler import profile, ProfilerActivity
from datetime import datetime
import os

num_threads = 4

# === ì„¤ì • ===
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
trace_file = f"profile_trace_{timestamp}_t{num_threads}_cpu.json"

# ë””ë°”ì´ìŠ¤ ì„¤ì •: CPUë§Œ ì‚¬ìš©
device = torch.device("cpu")
torch.manual_seed(0)
torch.set_num_threads(num_threads)

# ëª¨ë¸ ì¤€ë¹„
model = models.resnet50(weights=None).to(device)
model.train()

# ë°ì´í„°ì…‹ ì¤€ë¹„
transform = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor()
])
dataset = datasets.CIFAR10(root="../../data", train=True, transform=transform, download=True)
loader = torch.utils.data.DataLoader(dataset, batch_size=2, shuffle=True)

# ì†ì‹¤ í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì €
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.01)

# === Profiler ì‹¤í–‰ (CPUë§Œ) ===
with profile(
    activities=[ProfilerActivity.CPU],
    record_shapes=True,
    with_stack=True,
    with_flops=True,
    profile_memory=True
) as prof:
    for epoch in range(5):
        print(f"ðŸ” Epoch {epoch+1}")
        for step, (inputs, labels) in enumerate(loader):
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()

            with torch.autograd.profiler.record_function("model_forward"):
                outputs = model(inputs)

            with torch.autograd.profiler.record_function("model_loss"):
                loss = criterion(outputs, labels)

            with torch.autograd.profiler.record_function("model_backward"):
                loss.backward()

            optimizer.step()
            prof.step()

            # ì‹œê°„ ì ˆì•½: epochë‹¹ 10ê°œ ë°°ì¹˜ë§Œ ì²˜ë¦¬
            if step >= 99:
                break

# === JSON ì €ìž¥ ===
prof.export_chrome_trace(trace_file)
print(f"âœ… JSON trace saved to {trace_file}")
