import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models
import zmq, pickle

# ì„¤ì •
torch.manual_seed(42)
torch.use_deterministic_algorithms(True)
torch.set_num_threads(1)
device = torch.device("cpu")

# ëª¨ë¸ & ì˜µí‹°ë§ˆì´ì €
model = models.mobilenet_v2(weights=None).to(device)
model.train()
optimizer = optim.SGD(model.parameters(), lr=0.01)

# ë°ì´í„°
inputs = torch.randn(2, 3, 64, 64).to(device)
labels = torch.randint(0, 10, (2,)).to(device)

# forward
outputs = model(inputs)
outputs.retain_grad()
loss_fn = nn.CrossEntropyLoss()

# Bì—ê²Œ ë³´ë‚¼ outputë§Œ
payload = {
    "outputs": outputs.detach().cpu(),
    "labels": labels.cpu()
}

# ZeroMQ ì†¡ì‹ 
context = zmq.Context()
socket = context.socket(zmq.REQ)
socket.connect("tcp://10.32.137.71:5555")
socket.send(pickle.dumps(payload))
print("ğŸ“¤ Sent outputs to Node B")

# Aì—ì„œë„ âˆ‚L/âˆ‚outputs ê³„ì‚°
loss_a = loss_fn(outputs, labels)
loss_a.backward()
grad_a = outputs.grad.detach().clone().cpu()

# Bë¡œë¶€í„° ë°›ì€ grad ìˆ˜ì‹ 
reply = socket.recv()
grad_b = pickle.loads(reply)["outputs_grad"]
grad_b_tensor = torch.tensor(grad_b)

# 1ï¸âƒ£ gradient ë¹„êµ
print("\nğŸ“Š Comparing âˆ‚L/âˆ‚outputs")
if torch.allclose(grad_a, grad_b_tensor, atol=1e-6):
    print("âœ… Aì™€ Bì˜ outputs gradient ì¼ì¹˜")
else:
    diff = (grad_a - grad_b_tensor).abs()
    print(f"âŒ Gradient mismatch, max diff: {diff.max():.4e}")

# 2ï¸âƒ£ outputs.backward(grad_from_b) ìˆ˜í–‰ â†’ parameter.grad ìƒì„±
model.zero_grad()
outputs = model(inputs)  # ë‹¤ì‹œ forward
outputs.backward(grad_b_tensor)

# 3ï¸âƒ£ parameter update
optimizer.step()
print("âœ… A: model parameters updated using B's gradient")
