import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models, datasets, transforms
import zmq
import pickle
import numpy as np
from datetime import datetime

# ======================
# ì„¤ì •
# ======================
torch.manual_seed(0)
torch.set_num_threads(1)
device = torch.device("cpu")

# ======================
# ëª¨ë¸ ë° ì˜µí‹°ë§ˆì´ì €
# ======================
model = models.mobilenet_v2(weights=None).to(device)
model.train()

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.01)

# ======================
# CIFAR-10 ë°ì´í„° (64x64 ë³€í™˜)
# ======================
transform = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor()
])
dataset = datasets.CIFAR10(root="../data", train=True, transform=transform, download=True)
loader = torch.utils.data.DataLoader(dataset, batch_size=2, shuffle=True)

inputs, labels = next(iter(loader))
inputs, labels = inputs.to(device), labels.to(device)

# ======================
# Forward + Backward (ë‹¨, step()ì€ í•˜ì§€ ì•ŠìŒ)
# ======================
outputs = model(inputs)
loss = criterion(outputs, labels)
loss.backward()

# Gradient ì¶”ì¶œ (ì´ë¦„ ê¸°ì¤€)
named_grads = {
    name: p.grad.cpu().numpy() if p.grad is not None else None
    for name, p in model.named_parameters()
}

# ======================
# ZeroMQ: gradient + optimizer state ì „ì†¡
# ======================
context = zmq.Context()
socket = context.socket(zmq.REQ)
socket.connect("tcp://10.32.137.71:5555")  # Node B IP

data_to_send = {
    "grads": named_grads,
    "opt_state": optimizer.state_dict()
}

serialized_grads = pickle.dumps(data_to_send)
print(f"ğŸ“¦ Gradient total serialized size: {len(serialized_grads)/1024:.2f} KB")
print("ğŸ“¤ Node A: gradient ì „ì†¡ ì¤‘...")
socket.send(serialized_grads)

# Node Bë¡œë¶€í„° ì—…ë°ì´íŠ¸ëœ ëª¨ë¸ ìˆ˜ì‹ 
reply = socket.recv()
state_dict_b = pickle.loads(reply)
print("ğŸ“¥ Node A: Node B ëª¨ë¸ ìˆ˜ì‹  ì™„ë£Œ")

# ======================
# ëª¨ë¸ íŒŒë¼ë¯¸í„° ë¹„êµ
# ======================
state_dict_a = model.state_dict()
total = 0
matched = 0
mismatched_keys = []

for key in state_dict_a:
    a_tensor = state_dict_a[key]
    b_tensor = state_dict_b[key]
    total += 1
    if torch.allclose(a_tensor, b_tensor, atol=1e-6):
        matched += 1
    else:
        mismatched_keys.append(key)

match_rate = matched / total * 100
print(f"\nâœ… MATCHED: {matched}/{total} parameters ({match_rate:.2f}%)")

if mismatched_keys:
    print(f"âŒ MISMATCHED KEYS ({len(mismatched_keys)}):")
    for key in mismatched_keys:
        print(f" - {key}")

    # ë¡œê·¸ë¡œ ì €ì¥
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_path = "mismatch_log.txt"
    with open(log_path, "a") as f:
        mismatch_line = ", ".join(mismatched_keys)
        f.write(f"[{timestamp}]: {mismatch_line}\n")
    print(f"ğŸ“„ Mismatch keys appended to: {log_path}")
else:
    print("ğŸ‰ All parameters match exactly!")
